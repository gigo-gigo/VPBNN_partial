{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path(os.getcwd())\n",
    "base_path = str(base_path.parent)\n",
    "sys.path = [base_path] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"darkgrid\", palette=\"deep\", font=\"sans-serif\", font_scale=1.0, color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./img/\", exist_ok=True)\n",
    "os.makedirs(\"./score/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_experimental_environment(seed=6902):\n",
    "    K.clear_session()\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "    python_random.seed(seed)\n",
    "\n",
    "    # The below set_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see:\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: b'419.17'\n",
      "Device 0 : b'GeForce GTX 1070 Ti'\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "\n",
    "try:\n",
    "    nvmlInit()\n",
    "    print(\"Driver Version:\", nvmlSystemGetDriverVersion())\n",
    "    deviceCount = nvmlDeviceGetCount()\n",
    "    for i in range(deviceCount):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        print(\"Device\", i, \":\", nvmlDeviceGetName(handle))\n",
    "    nvmlShutdown()\n",
    "except NVMLError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version: 3.6.10.final.0 (64 bit)\n",
      "cpuinfo_version: [7, 0, 0]\n",
      "cpuinfo_version_string: 7.0.0\n",
      "arch: X86_64\n",
      "bits: 64\n",
      "count: 12\n",
      "arch_string_raw: AMD64\n",
      "vendor_id_raw: GenuineIntel\n",
      "brand_raw: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\n",
      "hz_advertised_friendly: 3.2000 GHz\n",
      "hz_actual_friendly: 3.1920 GHz\n",
      "hz_advertised: [3200000000, 0]\n",
      "hz_actual: [3192000000, 0]\n",
      "l2_cache_size: 1572864\n",
      "stepping: 10\n",
      "model: 158\n",
      "family: 6\n",
      "l3_cache_size: 12582912\n",
      "flags: ['3dnow', '3dnowprefetch', 'abm', 'acpi', 'adx', 'aes', 'apic', 'avx', 'avx2', 'bmi1', 'bmi2', 'clflush', 'clflushopt', 'cmov', 'cx16', 'cx8', 'de', 'dtes64', 'dts', 'erms', 'est', 'f16c', 'fma', 'fpu', 'fxsr', 'hle', 'ht', 'hypervisor', 'ia64', 'invpcid', 'lahf_lm', 'mca', 'mce', 'mmx', 'movbe', 'mpx', 'msr', 'mtrr', 'osxsave', 'pae', 'pat', 'pbe', 'pcid', 'pclmulqdq', 'pdcm', 'pge', 'pni', 'popcnt', 'pse', 'pse36', 'rdrnd', 'rdseed', 'rtm', 'sep', 'serial', 'smap', 'smep', 'ss', 'sse', 'sse2', 'sse4_1', 'sse4_2', 'ssse3', 'tm', 'tm2', 'tsc', 'vme', 'x2apic', 'xsave', 'xtpr']\n",
      "l2_cache_line_size: 256\n",
      "l2_cache_associativity: 6\n"
     ]
    }
   ],
   "source": [
    "from cpuinfo import get_cpu_info\n",
    "\n",
    "for key, value in get_cpu_info().items():\n",
    "    print(\"{0}: {1}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory: 15.92GB\n"
     ]
    }
   ],
   "source": [
    "import psutil \n",
    "\n",
    "mem = psutil.virtual_memory() \n",
    "print(\"memory: {0:.2f}GB\".format(mem.total / 1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAYES_MODELS = [\n",
    "    \"MNIST-CNN\",\n",
    "]\n",
    "\n",
    "LAST_ACTIVATIONS = [\n",
    "    \"sigmoid\",\n",
    "    \"softmax\",\n",
    "]\n",
    "\n",
    "PREDICTION_MODES = [\n",
    "    \"Normal-mode\",\n",
    "    \"Linear-mode\",\n",
    "    \"Independent-mode\",\n",
    "    \"Upper-mode\",\n",
    "    \"MC-mode\",\n",
    "]\n",
    "\n",
    "DATASETS = [\n",
    "    \"MNIST\",\n",
    "    \"Fashion\",\n",
    "    \"Kuzushiji\",\n",
    "    \"Kannada\",\n",
    "    \"EMNIST-MNIST\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    seed = 6902\n",
    "    train_domain = \"Fashion\"\n",
    "    bayes_model= BAYES_MODELS[0]\n",
    "    num_mc = 2000\n",
    "    optimizer = \"Adam\"\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 2048\n",
    "    max_epochs = 1\n",
    "    patience = 10\n",
    "    rhos = [0.0, 1.0e-5, 5.0e-5, 1.0e-4, 5.0e-4, 1.0e-3, 5.0e-3, 1.0e-2, 5.0e-2, 1.0e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kuzushiji_load_data():\n",
    "    ds = tfds.load(\n",
    "        \"kmnist\", split=[\"train\", \"test\"], shuffle_files=False, batch_size=-1\n",
    "    )\n",
    "    ds = tfds.as_numpy(ds)\n",
    "    y_train = ds[0][\"label\"].astype(\"uint8\")\n",
    "    x_train = ds[0][\"image\"].reshape((-1, 28, 28)).astype(\"uint8\")\n",
    "    y_test = ds[1][\"label\"].astype(\"uint8\")\n",
    "    x_test = ds[1][\"image\"].reshape((-1, 28, 28)).astype(\"uint8\")\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def kannada_load_data():\n",
    "    path = tf.keras.utils.get_file(\n",
    "        \"y_kannada_MNIST_train.npz\",\n",
    "        \"https://github.com/vinayprabhu/Kannada_MNIST/raw/master/data/output_tensors/MNIST_format/y_kannada_MNIST_train.npz\",\n",
    "    )\n",
    "    y_train = np.load(path)[\"arr_0\"]\n",
    "\n",
    "    path = tf.keras.utils.get_file(\n",
    "        \"X_kannada_MNIST_train.npz\",\n",
    "        \"https://github.com/vinayprabhu/Kannada_MNIST/raw/master/data/output_tensors/MNIST_format/X_kannada_MNIST_train.npz\",\n",
    "    )\n",
    "    x_train = np.load(path)[\"arr_0\"]\n",
    "\n",
    "    path = tf.keras.utils.get_file(\n",
    "        \"y_kannada_MNIST_test.npz\",\n",
    "        \"https://github.com/vinayprabhu/Kannada_MNIST/raw/master/data/output_tensors/MNIST_format/y_kannada_MNIST_test.npz\",\n",
    "    )\n",
    "    y_test = np.load(path)[\"arr_0\"]\n",
    "\n",
    "    path = tf.keras.utils.get_file(\n",
    "        \"X_kannada_MNIST_test.npz\",\n",
    "        \"https://github.com/vinayprabhu/Kannada_MNIST/raw/master/data/output_tensors/MNIST_format/X_kannada_MNIST_test.npz\",\n",
    "    )\n",
    "    x_test = np.load(path)[\"arr_0\"]\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def emnist_mnist_load_data():\n",
    "    ds = tfds.load(\n",
    "        \"emnist/mnist\", split=[\"train\", \"test\"], shuffle_files=False, batch_size=-1\n",
    "    )\n",
    "    ds = tfds.as_numpy(ds)\n",
    "    y_train = ds[0][\"label\"].astype(\"uint8\")\n",
    "    x_train = ds[0][\"image\"].reshape((-1, 28, 28)).astype(\"uint8\")\n",
    "    y_test = ds[1][\"label\"].astype(\"uint8\")\n",
    "    x_test = ds[1][\"image\"].reshape((-1, 28, 28)).astype(\"uint8\")\n",
    "\n",
    "    x_train = np.array([x.T for x in x_train])\n",
    "    x_test = np.array([x.T for x in x_test])\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "def load_dataset(dataset, val_size=1.0 / 6.0):\n",
    "    if dataset == DATASETS[0]:\n",
    "        load_data = keras.datasets.mnist.load_data\n",
    "    elif dataset == DATASETS[1]:\n",
    "        load_data = keras.datasets.fashion_mnist.load_data\n",
    "    elif dataset == DATASETS[2]:\n",
    "        load_data = kuzushiji_load_data\n",
    "    elif dataset == DATASETS[3]:\n",
    "        load_data = kannada_load_data\n",
    "    elif dataset == DATASETS[4]:\n",
    "        load_data = emnist_mnist_load_data\n",
    "    else:\n",
    "        raise ValueError(\"Error\")\n",
    "\n",
    "    # input image dimensions\n",
    "    num_classes = 10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "    if val_size > 0.0:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(\n",
    "            x_train, y_train, test_size=val_size, stratify=y_train\n",
    "        )\n",
    "    else:\n",
    "        x_val, y_val = x_train, y_train\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test), num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_softmax_entropy(prob):\n",
    "    entropy = np.sum(-prob * np.log(np.maximum(prob, 1.0e-7)), axis=-1)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calc_sigmoid_entropy(prob):\n",
    "    entropy = np.sum(\n",
    "        -prob * np.log(np.maximum(prob, 1.0e-7))\n",
    "        - (1.0 - prob) * np.log(np.maximum(1.0 - prob, 1.0e-7)),\n",
    "        axis=-1,\n",
    "    )\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_last_bayes_model(input_shape, output_shape, last_activation):\n",
    "    # https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "    inputs = keras.Input(input_shape)\n",
    "    conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation=\"relu\")(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    drop1 = layers.Dropout(0.25)(pool1)\n",
    "    flat1 = layers.Flatten()(drop1)\n",
    "    dense1 = layers.Dense(128, activation=\"relu\")(flat1)\n",
    "    drop2 = layers.Dropout(0.5)(dense1)\n",
    "    dense2 = layers.Dense(output_shape, activation=last_activation)(drop2)\n",
    "    model = keras.Model(inputs=inputs, outputs=dense2)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_bayes_model(bayes_model_name, input_shape, output_shape, last_activation):\n",
    "    if bayes_model_name == BAYES_MODELS[0]:\n",
    "        model = create_last_bayes_model(input_shape, output_shape, last_activation)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "50000/50000 - 5s - loss: 0.1220 - accuracy: 0.9533 - val_loss: 0.0663 - val_accuracy: 0.9746\n",
      "rho: 0.0, ll: 0.8545447587966919\n",
      "rho: 1e-05, ll: 0.8547410368919373\n",
      "rho: 5e-05, ll: 0.8555192351341248\n",
      "rho: 0.0001, ll: 0.8564772009849548\n",
      "rho: 0.0005, ll: 0.8635912537574768\n",
      "rho: 0.001, ll: 0.8712509870529175\n",
      "rho: 0.005, ll: 0.8992081880569458\n",
      "rho: 0.01, ll: 0.8863914608955383\n",
      "rho: 0.05, ll: 0.4436076283454895\n",
      "rho: 0.1, ll: 0.060839131474494934\n",
      "best_rho: 0.005, best_ll: 0.8992081880569458\n"
     ]
    }
   ],
   "source": [
    "from vpbnn import vlayers\n",
    "from vpbnn.models import nn2vpbnn\n",
    "\n",
    "seed = 6902\n",
    "last_activation = \"sigmoid\"\n",
    "\n",
    "set_experimental_environment(seed)\n",
    "\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test), num_classes = load_dataset(\n",
    "    args.train_domain\n",
    ")        \n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "model = create_bayes_model(\n",
    "    args.bayes_model, input_shape, num_classes, last_activation\n",
    ")\n",
    "\n",
    "if last_activation == \"softmax\":\n",
    "    loss_func = \"categorical_crossentropy\"\n",
    "    calc_entropy = calc_softmax_entropy\n",
    "elif last_activation == \"sigmoid\":\n",
    "    loss_func = \"binary_crossentropy\"\n",
    "    calc_entropy = calc_sigmoid_entropy\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=args.patience,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=loss_func, optimizer=args.optimizer, metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=args.train_batch_size,\n",
    "    epochs=args.max_epochs,\n",
    "    verbose=2,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[es],\n",
    ")\n",
    "\n",
    "if last_activation == \"sigmoid\":\n",
    "    best_rho = None\n",
    "    best_ll = -np.inf\n",
    "    for rho in args.rhos:\n",
    "        vmodel = nn2vpbnn(model, variance_mode=3, rho=rho)\n",
    "        y_prob, y_var = vmodel.predict(x_val, batch_size=args.test_batch_size)\n",
    "        ll = -0.5 * np.square(y_val - y_prob) / np.maximum(y_var, 1.0e-7) - 0.5 * np.log(2.0 * np.pi) - 0.5 * np.log(np.maximum(y_var, 1.0e-7))\n",
    "        ll = ll.mean()\n",
    "        print(\"rho: {0}, ll: {1}\".format(rho, ll))                \n",
    "        if ll > best_ll:\n",
    "            best_rho = rho\n",
    "            best_ll = ll\n",
    "    print(\"best_rho: {0}, best_ll: {1}\".format(best_rho, best_ll))\n",
    "    vmodel = nn2vpbnn(model, rho=best_rho)\n",
    "else:\n",
    "    vmodel = nn2vpbnn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_predict(vmodel, num_mc):\n",
    "    for _ in range(num_mc):\n",
    "        _ = vmodel.predict(x_test, batch_size=args.test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VPBNN-Mode (adaptive rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 ms ± 31.7 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "for layer in vmodel.layers:\n",
    "    if isinstance(layer, vlayers.VarianceLayer):\n",
    "        layer.variance_mode = 3\n",
    "vmodel.compile(loss=loss_func)\n",
    "%timeit -r 10 -n 1 vmodel.predict(x_test, batch_size=args.test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC-Mode (T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 s ± 16.5 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "for layer in vmodel.layers:\n",
    "    if isinstance(layer, vlayers.VarianceLayer):\n",
    "        layer.variance_mode = 4\n",
    "vmodel.compile(loss=loss_func)\n",
    "%timeit -r 10 -n 1 mc_predict(vmodel, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC-Mode (T=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6 s ± 28.3 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "for layer in vmodel.layers:\n",
    "    if isinstance(layer, vlayers.VarianceLayer):\n",
    "        layer.variance_mode = 4\n",
    "vmodel.compile(loss=loss_func)\n",
    "%timeit -r 10 -n 1 mc_predict(vmodel, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC-Mode (T=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.3 s ± 13.7 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "for layer in vmodel.layers:\n",
    "    if isinstance(layer, vlayers.VarianceLayer):\n",
    "        layer.variance_mode = 4\n",
    "vmodel.compile(loss=loss_func)\n",
    "%timeit -r 10 -n 1 mc_predict(vmodel, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC-Mode (T=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 s ± 36.4 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "for layer in vmodel.layers:\n",
    "    if isinstance(layer, vlayers.VarianceLayer):\n",
    "        layer.variance_mode = 4\n",
    "vmodel.compile(loss=loss_func)\n",
    "%timeit -r 10 -n 1 mc_predict(vmodel, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
